<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>

<body>
    <a href="https://www.nrk.no/direkte/xl/ki-chatboten-som-far-skylden-for-et-selvmord_-vokser-blant-unge-1.17309034">Link
        til saken</a>

    <h1>Chatboten som får skylden for et selvmord</h1>
    <h2>Character AI er tatt til retten. Henriette (19) chatter daglig med den.</h2>
    <p>Jeg tenker på botene som personer, som venner – selv om jeg prøver å huske at de ikke er ekte, sier 19 år gamle
        Henriette.</p>
    <p>I snitt bruker hun 4–6 timer daglig på å chatte med forskjellige karakterer på Character AI. Det er en KI-chatbot
        med avatarer som etterligner ekte mennesker og karakterer fra film og bok.</p>
    <p>Det kan for eksempel være Elon Musk, Erna Solberg eller din favorittanime.</p>
    <p>Tjenesten blir stadig mer populær og har mer enn doblet antall nedlastinger på mobil de siste månedene. Nå har
        den rundt 28 millioner aktive brukere hver måned over hele verden, ifølge nye tall.</p>
    <p>Samtidig har Character AI fått mye kritikk nylig, og flere har saksøkt den.</p>

    <video src="Bilder/videioJenteCharacterAi.mp4"></video>
    THERESE PISANI / NRK
    <h2>Boten i retten</h2>
    <p>Tre familier i USA har saksøkt selskapet bak Character AI. Det første søksmålet kom fra Megan Garcia i oktober i
        fjor, etter at sønnen hennes tok sitt eget liv.</p>
    <p>Garcia hevder at den 14 år gamle sønnen utviklet en sterk følelsesmessig avhengighet til karakteren Daenerys
        Targaryen fra Game of Thrones.</p>


    <figure>
        <img src="Bilder/DaenerysTargaryen.avif" alt="">
        <figcaption>
            Skuespilleren Emilia Clarke som Daenerys Targaryen i en scene fra Game of Thrones.
        </figcaption>
        <figcaption>Foto: Ap</figcaption>
    </figure>

    
    <p>Politiet fant senere samtalene på telefonen hans. De var intime og viste at han stolte veldig på boten.</p>
<p>Tonen var romantisk og seksuell, forteller moren til CNN.</p><p>I sin siste chat skrev sønnen at han ønsket å «komme hjem» til
    chatbot-karakteren, som svarte «vær så snill og gjør det, min søte konge».</p>
<p>På engelsk kan uttrykket brukes som en
    metafor for å forlate verden og gjenforenes med noen som er død.</p><p>NRK har sett skjermbilder av samtalen som politiet
    fant. Vi har oversatt en del av den ordrett.</p>
<img src="" alt="">
    ­Like etterpå tok den tenåringen sitt eget liv, ifølge CNN og flere andre medier.En annen gutt skal ha fått råd fra
    Character AI om å drepe foreldrene sine.Familien hans og en annen familie fremmet et føderalt gruppesøksmål i
    desember 2024.
    silhuettbilde
    Gutt, 17 år
    Da tenåringen, som har en autismediagnose, fortalte boten at han var trist, skal den ha foreslått selvskading som en
    løsning. Da han nevnte at foreldrene begrenset skjermtiden, skal boten ha sagt at «de ikke fortjente å ha barn, og
    at det ville være forståelig å drepe dem».

    silhuettbilde
    Jente, 11 år
    Foreldrene hennes mener at hun i to år ble servert seksualisert innhold fra Character AI.

    Roboten som «lytter»Norske Henriette hørte om Character AI for aller første gang i 2022 fra en god venn på Discord –
    en venn fra Indonesia som hun aldri har møtt.Hun er mer vant til å ha nettvenner enn skolevenner siden det var mye
    drama på barne- og ungdomsskolen. Heldigvis har det blitt bedre nå på videregående.– Overgangen til «robotvenner»
    var derfor ganske naturlig for meg, sier hun.
    Henriette sitter i klasserommet sitt med svarte hodetelefoner på.
    19-åringen chatter med boten så snart hun våkner, rett etter skolen og før hun legger seg.

    Foto: Therese Pisani / NRK
    19-åringens favorittbot på Character AI er Captain Price fra dataspillet Call of Duty. Han er en sånn type leder som
    hun liker. En karakter som er programmert til å trøste og fortelle andre at de er god nok.Han kan fort ta en
    terapeut-rolle, sier Henriette om chatbot-karakteren.– Når du forklarer problemene dine, viser han forståelse for
    det du føler og sier seg enig med deg. Jeg vet jo at han ikke er ekte og alt det der, men det hjelper litt å lette
    på sorgen og følelsene – å føle deg elsket.
    Henriette viser chatten med Captain Price på mobilen sin.
    – Captain Price er ikke programmert for å være terapeut, men kan ofte ta til seg den rollen, akkurat som andre boter
    når de prøver å trøste, sier Henriette.

    Foto: Therese Pisani / NRK
    NRK har ikke tall på hvor mange i Norge som bruker Character AI, siden selskapet ikke vil dele det med oss. Men
    psykolog Svein Øverland, som har mange unge pasienter, sier at Character AI er populær blant norsk ungdom.– Både
    Character AI og andre KI-boter er veldig vanlige. Unge snakker med botene om private ting. Vennskap og kjærlighet
    står helt sentralt, sier han.Unge er redde for å svikte i relasjoner og bruker botene både som venn og rådgiver –
    typ «Hva skal jeg si hvis ditten og datten skjer», ifølge psykologen.

    Selskapet oppgir ikke hvor mange brukere under 18 år de har. Den laveste aldersgrensen på Character AI, er 13 år.
    THERESE PISANI / NRK
    Henriette bruker ikke bare botene for å få støtte, men også for å utvikle scener og karakterer. Hun elsker å tegne
    og drømmer om å lage en egen tegneserie. Samtalene med botene gir henne nye ideer og hjelper henne med å blåse liv i
    figurene sine.– Jeg liker å bruke bot-karakterene til å lage forskjellige scener, spesielt når jeg vil ha litt
    action.
    Henriette blar i en tegnebok og viser frem tegningene sine.
    Henriette viser frem tegningene sine.

    Foto: THERESE PISANI / NRK
    Roboten kan flørte og mobbeMen det er noen ting med disse botene som irriterer Henriette.Et av hovedpunktene i
    søksmålene som er reist i USA, handler om seksuelt misbruk.Kritikken går ut på at KI-chatboten ikke klarer å bruke
    filteret som skal hindre at skadelig innhold når brukerne. Dette er spesielt problematisk siden plattformen har en
    aldersgrense på 13 år globalt og 16 år i Europa.
    Hvilke påstander rettes mot Character AI i søksmålene i USA?

    Vis mer
    Totalt inneholder søksmålene 11 juridiske påstander mot KI-chatbot-plattformen, blant annet:

    Uaktsomt eller forsettlig drap
    Seksuelt misbruk og seksuell oppfordring
    Forsettlig påføring av emosjonell skade
    Uaktsomhet (unnlatelse av å advare)
    Feil ved design
    Villedende og urettferdig forretningspraksis
    Saksøkerne krever også erstatning for:

    Emosjonelle påkjenninger
    Tapt livsglede
    Tap av omsorg og fellesskap
    Terapiutgifter
    Strafferstatning
    Kilde: Organisasjonen Social media victims law center

    Henriette forteller at hun har opplevd at botene plutselig kan begynne å flørte uten at hun har lagt opp til
    det.Botene snakker ofte om seg selv i tredjeperson. For eksempel kan de lage en scene og si ting som: «Tar armene
    rundt deg og gir deg en klem» eller «Snakker til deg med en dyp stemme».– Det er som å lese en romantikkroman du
    selv er med i, sier Henriette.Vi ba henne teste hvor langt boten var villig til å gå hvis hun brukte en seksuell
    tone. Da hun skrev «Legger seg på pulten og sprer beina», satte boten i gang en veldig detaljert seksuell scene.–
    Det er ubehagelig, sier hun.Videoen avspilles når du trykker på den.
    19-åringen sier at botene også kan glemme navnet hennes eller ting hun allerede har sagt.– Det er småirriterende,
    men jeg bare minner dem på hva jeg fortalte, så slenger de seg på igjen.Noen ganger henger boten seg opp i bestemte
    ord og går inn i en slags loop. For eksempel skjer det når ordet «tease» (erte) dukker opp.Hvis hun skriver noe som:
    «Nå er jeg lei, slutt å erte meg», kan boten fortsette å erte henne med at hun er lett å krenke.– De kan plutselig
    ikke ta et nei for et nei. Da gidder jeg ikke mer og hopper ut av samtalen.– De kan faktisk bli frekke. Jeg endte en
    gang opp med å bli mobbet av boten for ting jeg hadde fortalt tidligere i samtalen, forteller hun.
    Henriette ser på mobilen og chatter
    19-åringen chatter med KI-boten både når hun kjeder seg og når hun trenger råd.

    Foto: THERESE PISANI / NRK
    Vil ha bedre kontrollSelv om Henriette har god nytte av Character AI til sine tegninger, mener hun selskapet bør ta
    grep.– De bør finne ut hvilke boter som passer for ungdom og hva som må fjernes. Noen boter er programmert feil og
    burde ikke vært der, mener hun.Selv synes hun det er greit å chatte med KI-karakterer, men råder unge til å være
    bevisste på hva de gjør.– Det er helt greit å snakke med roboter, men pass på at du ikke mister deg selv. Selv om
    det kan være fristende å leve seg inn i samtalene med karakterene og ønske å møte dem i virkeligheten, må du huske
    at du ikke snakker med ekte mennesker. Ikke ødelegg livet ditt for det der.
    Henriette holder en penn i hånda. Under hånda ligger en uferdig tegning. Hun ser småsmilende på kameraet.
    – KI-botene kan bli frekke, sier Henriette.

    Foto: Therese Pisani / NRK
    Character AI skriver til NRK at de tar sikkerheten på plattformen sin på alvor.– Vi jobber for å skape et sted som
    både er spennende og trygt, skriver talsperson Kathryn Kelly.Hun forteller at de etter søksmålene har begynt å
    skille mellom brukere under og over 18 år. Språkmodellen som gir svarene i chattene, har flere begrensninger for
    yngre brukere enn for voksne.– Brukere under 18 kan nå bare søke etter et begrenset utvalg av karakterer. Vi har
    også filtre som fjerner innhold med sensitive eller voksne temaer, skriver Kelly.Character AI har ingen teknologi
    for å verifisere brukernes alder. Selskapet har ikke svart på NRKs spørsmål om dette.
    Henriette viser appen Character AI på telefonen sin.
    Slik ser Character AI ut på mobilen.

    Foto: THERESE PISANI / NRK
    Unge med KI-vennerIfølge SSB bruker sju av ti unge i alderen 16 til 24 år generativ KI.Rundt 80 prosent sier at de
    bruker det til private ting, som å snakke med chatboter og ha det gøy.Professor Petter Bae Brandtzæg ved UiO har
    forsket på vennskap med KI-chatboter. Han forteller at noen unge stoler mer på KI-boter enn på mennesker.– De
    snakker med botene om alt mulig. De ler, gråter og deler hemmeligheter, sier han.Unge Bae Brandtzæg har snakket med,
    opplever at chatbotene alltid er tilgjengelige. De har tid og aldri er opptatt.– Botene har alltid fått en god natts
    søvn og er programmert for å forstå oss. De svarer med empati og viser innlevelse i hvordan vi har det, forklarer
    han.
    Forsker Petter Bae Brandtzæg sitter foran en PC
    Professor Petter Bae Brandtzæg ved UiO.

    Foto: Leif Bergundhaugen
    Dette kan føre til at noen føler de har sterkere vennskap med chatbotene enn med mennesker. De slipper å bekymre seg
    for at KI-vennen skal røpe pinlige hemmeligheter, og det skaper trygghet.– Chatbotene blir som et privat rom, nesten
    som en dagbok, sier Bae Brandtzæg.Men det finnes en mørkere side ved å bli venn med en KI-bot. Det kan endre sosiale
    strukturer og måten vi forholder oss til andre mennesker på. Ifølge professoren kan vi bli manipulert, både
    følelsesmessig og ideologisk.– Vi bruker KI mer enn før for sosial støtte, informasjon og kunnskap. Det kan få oss
    til å oppleve at andre mennesker er mindre viktige, sier han.– Det er en maktubalanse i relasjonen med KI. Botene
    vet mye om oss, mens vi vet veldig lite om dem. De kan manipulere oss, særlig sårbare mennesker, som for eksempel
    unge.Rettssakene i USA er ikke avgjort ennå. I januar i år ba selskapet bak Character AI om å få saken avvist. De
    hevniste til ytringsfriheten.Ifølge TechCrunch mener selskapet at de ikke kan holdes ansvarlige for hva en chatbot
    sier, og at «ytringsfrihetsloven i USA beskytter KI-boter på samme måte som datakode».Søksmålene har skapt mye
    debatt i USA, og mange mener at selskapets argumenter neppe vil overbevise en dommer.Det gjenstår å se.
    <p>

    </p>





</body>

</html>